{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd4e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.model_impl import WCMSLModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26aa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WCMSLModel()\n",
    "model.load(PROJECT_ROOT / \"src\" / \"models\" / \"wcmsl_base.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0acc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (a := input(\"Enter text (or 'exit' to quit): \")) not in (\"exit\", ''):\n",
    "    prediction = model.predict(a)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acfd56e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 601/3000 [00:03<00:11, 200.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df1.iterrows(), total=\u001b[38;5;28mall\u001b[39m):\n\u001b[32m     12\u001b[39m     text, ai = row[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m], row[\u001b[33m'\u001b[39m\u001b[33mgenerated\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     prediction = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m     15\u001b[39m     prediction_test = \u001b[33m\"\u001b[39m\u001b[33mAI\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ai == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mHUMAN\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prediction_test == prediction:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Arsenij1\\human-vs-ai-text-classifier\\src\\model_impl\\mixin.py:54\u001b[39m, in \u001b[36mBaseModelMixin.predict\u001b[39m\u001b[34m(self, text, result_ai_ge)\u001b[39m\n\u001b[32m     49\u001b[39m style_metrics = \u001b[38;5;28mvars\u001b[39m(TextMetricCalculator(text).all_metrics)\n\u001b[32m     50\u001b[39m sample_df = pd.DataFrame(\n\u001b[32m     51\u001b[39m     [{**{\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text}, **style_metrics}]\n\u001b[32m     52\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m proba = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     56\u001b[39m probability_ai = proba[\u001b[32m1\u001b[39m]\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ModelPredictionCounter(probability_ai, result_ai_ge).prediction\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:858\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict_proba(Xt, **params)\n\u001b[32m    861\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1112\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[32m   1109\u001b[39m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros((n_samples, \u001b[32m0\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1143\u001b[39m, in \u001b[36mColumnTransformer._hstack\u001b[39m\u001b[34m(self, Xs, n_samples)\u001b[39m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1139\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFor a sparse output, all columns should \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1140\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbe a numeric or convertible to a numeric.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1141\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_Xs\u001b[49m\u001b[43m)\u001b[49m.tocsr()\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1145\u001b[39m     Xs = [f.toarray() \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(f) \u001b[38;5;28;01melse\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Xs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_construct.py:1056\u001b[39m, in \u001b[36mhstack\u001b[39m\u001b[34m(blocks, format, dtype)\u001b[39m\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_spmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_construct.py:1261\u001b[39m, in \u001b[36m_block\u001b[39m\u001b[34m(blocks, format, dtype, return_spmatrix)\u001b[39m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[32m   1260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m blocks[i,j] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m         A = \u001b[43mcoo_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1262\u001b[39m         blocks[i,j] = A\n\u001b[32m   1263\u001b[39m         block_mask[i,j] = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_coo.py:74\u001b[39m, in \u001b[36m_coo_base.__init__\u001b[39m\u001b[34m(self, arg1, shape, dtype, copy, maxprint)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m.has_canonical_format = arg1.has_canonical_format\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     coo = \u001b[43marg1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtocoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.coords = \u001b[38;5;28mtuple\u001b[39m(coo.coords)\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = coo.data.astype(getdtype(dtype, coo), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_csr.py:64\u001b[39m, in \u001b[36m_csr_base.tocoo\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtocoo\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     A = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtocoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# CSR-to-COO conversion always preserves [non-]canonicity\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# (indices sorting, presense of duplicate elements).\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Handled here instead of _cs_matrix because CSC-to-COO generally does not.\u001b[39;00m\n\u001b[32m     68\u001b[39m     A.has_canonical_format = \u001b[38;5;28mself\u001b[39m.has_canonical_format\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:996\u001b[39m, in \u001b[36m_cs_matrix.tocoo\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    993\u001b[39m expandptr(major_dim, \u001b[38;5;28mself\u001b[39m.indptr, major_indices)\n\u001b[32m    994\u001b[39m coords = \u001b[38;5;28mself\u001b[39m._swap((major_indices, minor_indices))\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coo_container\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_coo.py:103\u001b[39m, in \u001b[36m_coo_base.__init__\u001b[39m\u001b[34m(self, arg1, shape, dtype, copy, maxprint)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._shape) > \u001b[32m2\u001b[39m:\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mself\u001b[39m.coords = \u001b[38;5;28mtuple\u001b[39m(idx.astype(np.int64, copy=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coords)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\scipy\\sparse\\_coo.py:226\u001b[39m, in \u001b[36m_coo_base._check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx.max() >= \u001b[38;5;28mself\u001b[39m.shape[i]:\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33maxis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx.max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exceeds \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    225\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmatrix dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.shape[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m < \u001b[32m0\u001b[39m:\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnegative axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx.min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:45\u001b[39m, in \u001b[36m_amin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     44\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#df1 = pd.read_csv(PROJECT_ROOT / \"data\" / \"processed\" / \"balanced_length_filtered_test_dataset.csv\")\n",
    "df1 = pd.read_csv(PROJECT_ROOT / \"data\" / \"processed\" / \"balanced_length_filtered_test_dataset.csv\")\n",
    "\n",
    "all = len(df1)\n",
    "correct = 0\n",
    "\n",
    "for _, row in tqdm(df1.iterrows(), total=all):\n",
    "    text, ai = row['text'], row['generated']\n",
    "    prediction = model.predict(text).result\n",
    "\n",
    "    prediction_test = \"AI\" if ai == 1 else \"HUMAN\"\n",
    "    \n",
    "    if prediction_test == prediction:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / all\n",
    "print(f\"Accuracy on AI Generated Essays Dataset: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

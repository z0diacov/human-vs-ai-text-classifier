{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a61be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (70000, 3)\n",
      "generated\n",
      "0.0    35000\n",
      "1.0    35000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text metrics: 100%|██████████| 70000/70000 [00:16<00:00, 4367.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics DataFrame shape: (70000, 15)\n",
      "   word_count  text_length  sentence_count  avg_sentence_length  \\\n",
      "0         312         1452              16             3.586538   \n",
      "1         346         2051              18             4.809249   \n",
      "2         324         1825              22             4.320988   \n",
      "3         354         1832              21             4.084746   \n",
      "4         319         1597              17             3.937304   \n",
      "\n",
      "   avg_word_length  vocab_size  vocab_richness  repetition_ratio  \\\n",
      "0         4.653846         125        0.400641          0.599359   \n",
      "1         5.927746         187        0.540462          0.459538   \n",
      "2         5.632716         157        0.484568          0.515432   \n",
      "3         5.175141         146        0.412429          0.587571   \n",
      "4         5.006270         127        0.398119          0.601881   \n",
      "\n",
      "   punctuation_ratio  exclamation_ratio  question_ratio  uppercase_word_ratio  \\\n",
      "0           0.015152           0.001377        0.000000                   0.0   \n",
      "1           0.018528           0.000000        0.000000                   0.0   \n",
      "2           0.043836           0.003288        0.000548                   0.0   \n",
      "3           0.025109           0.000000        0.000000                   0.0   \n",
      "4           0.017533           0.000000        0.000000                   0.0   \n",
      "\n",
      "    entropy  stopwords_ratio  generated  \n",
      "0  6.304388         0.634615        0.0  \n",
      "1  6.945962         0.404624        0.0  \n",
      "2  6.629855         0.515432        0.0  \n",
      "3  6.693811         0.562147        0.0  \n",
      "4  6.480920         0.573668        0.0  \n",
      "\n",
      "Feature matrix shape: (70000, 14)\n",
      "Target distribution:\n",
      " generated\n",
      "0.0    35000\n",
      "1.0    35000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train size: (52500, 14)\n",
      "Test size: (17500, 14)\n",
      "\n",
      "===== MODEL PERFORMANCE =====\n",
      "Accuracy : 0.8261\n",
      "Precision: 0.8261\n",
      "Recall   : 0.8261\n",
      "F1-score : 0.8261\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Human-written       0.83      0.83      0.83      8750\n",
      " AI-generated       0.83      0.83      0.83      8750\n",
      "\n",
      "     accuracy                           0.83     17500\n",
      "    macro avg       0.83      0.83      0.83     17500\n",
      " weighted avg       0.83      0.83      0.83     17500\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[7228 1522]\n",
      " [1522 7228]]\n",
      "\n",
      "===== FEATURE IMPORTANCE (LogReg coefficients) =====\n",
      "avg_word_length         9.434629\n",
      "text_length            -8.219283\n",
      "word_count              3.499184\n",
      "vocab_size              2.591266\n",
      "avg_sentence_length     1.490214\n",
      "punctuation_ratio       1.375072\n",
      "vocab_richness         -1.295744\n",
      "repetition_ratio        1.295744\n",
      "exclamation_ratio       0.736256\n",
      "entropy                -0.628187\n",
      "sentence_count         -0.375803\n",
      "stopwords_ratio         0.227778\n",
      "question_ratio         -0.119549\n",
      "uppercase_word_ratio    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# BASELINE MODEL TRAINING (STYLE METRICS ONLY)\n",
    "# =====================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent if \"__file__\" in globals() else Path().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.features.text_metrics import TextMetricCalculator\n",
    "from src.config.config import config\n",
    "\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA\n",
    "# =========================\n",
    "\n",
    "df = pd.read_csv(\n",
    "    PROJECT_ROOT / \"data\" / \"processed\" / \"balanced_length_filtered_dataset.csv\"\n",
    ")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df[\"generated\"].value_counts())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# BUILD METRICS DATAFRAME\n",
    "# =========================\n",
    "\n",
    "def build_metrics_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"text\",\n",
    "    label_col: str = \"generated\",\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting text metrics\"):\n",
    "        calculator = TextMetricCalculator(row[text_col])\n",
    "        metrics = calculator.all_metrics\n",
    "\n",
    "        metrics_dict = vars(metrics)\n",
    "        metrics_dict[label_col] = row[label_col]\n",
    "\n",
    "        rows.append(metrics_dict)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "metrics_df = build_metrics_dataframe(df)\n",
    "\n",
    "print(\"\\nMetrics DataFrame shape:\", metrics_df.shape)\n",
    "print(metrics_df.head())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# FEATURE / TARGET SPLIT\n",
    "# =========================\n",
    "\n",
    "TARGET_COL = \"generated\"\n",
    "\n",
    "X = metrics_df.drop(columns=[TARGET_COL])\n",
    "y = metrics_df[TARGET_COL]\n",
    "\n",
    "print(\"\\nFeature matrix shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TRAIN / TEST SPLIT\n",
    "# =========================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"\\nTrain size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MODEL PIPELINE\n",
    "# =========================\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TRAIN\n",
    "# =========================\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EVALUATION\n",
    "# =========================\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n===== MODEL PERFORMANCE =====\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Human-written\", \"AI-generated\"]))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# FEATURE IMPORTANCE\n",
    "# =========================\n",
    "\n",
    "feature_importance = pd.Series(\n",
    "    pipeline.named_steps[\"classifier\"].coef_[0],\n",
    "    index=X.columns,\n",
    ").sort_values(key=np.abs, ascending=False)\n",
    "\n",
    "print(\"\\n===== FEATURE IMPORTANCE (LogReg coefficients) =====\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df2e193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (70000, 3)\n",
      "generated\n",
      "0    35000\n",
      "1    35000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text metrics: 100%|██████████| 70000/70000 [00:13<00:00, 5218.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style features: ['word_count', 'text_length', 'sentence_count', 'avg_sentence_length', 'avg_word_length', 'vocab_size', 'vocab_richness', 'repetition_ratio', 'punctuation_ratio', 'exclamation_ratio', 'question_ratio', 'uppercase_word_ratio', 'entropy', 'stopwords_ratio']\n",
      "\n",
      "Training combined model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Arsenij1\\human-vs-ai-text-classifier\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "\n",
      "===== MODEL PERFORMANCE =====\n",
      "Accuracy : 0.9915\n",
      "Precision: 0.9935\n",
      "Recall   : 0.9896\n",
      "F1-score : 0.9915\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Human       0.99      0.99      0.99      8750\n",
      "          AI       0.99      0.99      0.99      8750\n",
      "\n",
      "    accuracy                           0.99     17500\n",
      "   macro avg       0.99      0.99      0.99     17500\n",
      "weighted avg       0.99      0.99      0.99     17500\n",
      "\n",
      "Confusion matrix:\n",
      "[[8693   57]\n",
      " [  91 8659]]\n",
      "\n",
      "Model saved to: D:\\Arsenij1\\human-vs-ai-text-classifier\\models\\combined_tfidf_style_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# HUMAN vs AI TEXT CLASSIFIER\n",
    "# TF-IDF + STYLOMETRIC FEATURES (COMBINED MODEL)\n",
    "# =====================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- project imports ----\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.features.text_metrics import TextMetricCalculator\n",
    "from src.config.config import config\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PATHS\n",
    "# =====================================================\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"balanced_length_filtered_dataset.csv\"\n",
    "MODEL_PATH = PROJECT_ROOT / \"models\" / \"combined_tfidf_style_model.joblib\"\n",
    "MODEL_PATH.parent.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# LOAD DATA\n",
    "# =====================================================\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.dropna(subset=[\"text\", \"generated\"])\n",
    "\n",
    "df[\"generated\"] = df[\"generated\"].astype(int)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df[\"generated\"].value_counts())\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# BUILD STYLE METRICS\n",
    "# =====================================================\n",
    "\n",
    "def build_metrics_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"text\",\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for text in tqdm(df[text_col], desc=\"Extracting text metrics\"):\n",
    "        metrics = TextMetricCalculator(text).all_metrics\n",
    "        rows.append(vars(metrics))\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "style_df = build_metrics_dataframe(df)\n",
    "\n",
    "STYLE_FEATURES = style_df.columns.tolist()\n",
    "\n",
    "print(\"Style features:\", STYLE_FEATURES)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# FINAL DATAFRAME\n",
    "# =====================================================\n",
    "\n",
    "full_df = pd.concat(\n",
    "    [\n",
    "        df[[\"text\", \"generated\"]].reset_index(drop=True),\n",
    "        style_df.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X = full_df.drop(columns=[\"generated\"])\n",
    "y = full_df[\"generated\"]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# TRAIN / TEST SPLIT\n",
    "# =====================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# COLUMN TRANSFORMER\n",
    "# =====================================================\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"tfidf\",\n",
    "            TfidfVectorizer(\n",
    "                lowercase=True,\n",
    "                stop_words=\"english\",\n",
    "                max_features=20000,\n",
    "                ngram_range=(1, 2),\n",
    "                min_df=5,\n",
    "                max_df=0.9,\n",
    "            ),\n",
    "            \"text\",\n",
    "        ),\n",
    "        (\n",
    "            \"style\",\n",
    "            StandardScaler(),\n",
    "            STYLE_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PIPELINE\n",
    "# =====================================================\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"features\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# TRAINING\n",
    "# =====================================================\n",
    "\n",
    "print(\"\\nTraining combined model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training finished.\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# EVALUATION\n",
    "# =====================================================\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n===== MODEL PERFORMANCE =====\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score : {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Human\", \"AI\"]))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# SAVE MODEL\n",
    "# =====================================================\n",
    "\n",
    "joblib.dump(pipeline, MODEL_PATH)\n",
    "print(f\"\\nModel saved to: {MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# INFERENCE\n",
    "# =====================================================\n",
    "\n",
    "def predict_text(text: str) -> dict:\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "\n",
    "    style_metrics = vars(TextMetricCalculator(text).all_metrics)\n",
    "    sample_df = pd.DataFrame(\n",
    "        [{**{\"text\": text}, **style_metrics}]\n",
    "    )\n",
    "\n",
    "    proba = model.predict_proba(sample_df)[0]\n",
    "    pred = model.predict(sample_df)[0]\n",
    "\n",
    "    return {\n",
    "        \"prediction\": \"AI-generated\" if pred == 1 else \"Human-written\",\n",
    "        \"probability_ai\": float(proba[1]),\n",
    "        \"probability_human\": float(proba[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# EXAMPLE\n",
    "# =====================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83cf80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SAMPLE PREDICTION =====\n",
      "{'prediction': 'Human-written', 'probability_ai': 5.5622566591327496e-05, 'probability_human': 0.9999443774334087}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\n",
    "    123\n",
    "    \"\"\"\n",
    "\n",
    "    result = predict_text(sample_text)\n",
    "    print(\"\\n===== SAMPLE PREDICTION =====\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a79d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on AI Generated Essays Dataset: 0.0568\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(PROJECT_ROOT / \"data\" / \"raw\" / \"AI Generated Essays Dataset.csv\")\n",
    "\n",
    "all = len(df1)\n",
    "correct = 0\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    text, ai = row['text'], row['generated']\n",
    "    prediction = predict_text(text)['probability_ai']\n",
    "\n",
    "    if prediction > 0.7:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "\n",
    "    if prediction == ai:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / all\n",
    "print(f\"Accuracy on AI Generated Essays Dataset: {accuracy:.4f}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
